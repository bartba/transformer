# 1. Import Libraries
import os
import json
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from accelerate import Accelerator
from transformers import DetrForObjectDetection, DetrImageProcessor
from PIL import Image
import torchvision.transforms as T
from tqdm import tqdm
import matplotlib.pyplot as plt
from IPython.display import clear_output
import numpy as np

# 2. Custom COCO Dataset Class
class COCODetectionDataset(Dataset):
    def __init__(self, annotation_file, image_dir, processor, transforms=None):
        # Load COCO annotations
        with open(annotation_file, 'r') as f:
            self.coco = json.load(f)
        self.image_dir = image_dir
        self.processor = processor
        self.transforms = transforms
        self.image_ids = [img['id'] for img in self.coco['images']]
        # Map image_id to annotations for quick lookup
        self.annotations = {}
        for ann in self.coco['annotations']:
            img_id = ann['image_id']
            if img_id not in self.annotations:
                self.annotations[img_id] = []
            self.annotations[img_id].append(ann)

    def __len__(self):
        return len(self.image_ids)

    def __getitem__(self, idx):
        img_id = self.image_ids[idx]
        img_info = next(img for img in self.coco['images'] if img['id'] == img_id)
        img_path = os.path.join(self.image_dir, img_info['file_name'])
        image = Image.open(img_path).convert('RGB')

        # Apply additional transforms if provided
        if self.transforms:
            image = self.transforms(image)

        # Get annotations for this image
        anns = self.annotations.get(img_id, [])
        coco_anns = {
            'image_id': img_id,
            'annotations': anns
        }

        # Process image and annotations with DetrImageProcessor
        encoding = self.processor(images=image, annotations=coco_anns, return_tensors="pt")
        # Remove batch dimension
        encoding = {k: v.squeeze(0) for k, v in encoding.items()}
        encoding['size'] = torch.tensor([img_info['height'], img_info['width']])
        return encoding

# 3. Collate Function for Padding
def collate_fn(batch):
    processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
    return processor.pad(batch, return_tensors="pt")

# 4. Initialize Accelerator, Model, and Optimizer
accelerator = Accelerator()
device = accelerator.device
device_lr = 1e-4
batch_size = 2
num_epochs = 10
patience = 3  # For early stopping

processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")
optimizer = AdamW(model.parameters(), lr=device_lr)

# 5. Load COCO Dataset
image_dir = "/path/to/coco/train2017"  # Update with your path
train_annotation_file = "/path/to/coco/annotations/instances_train2017.json"
val_annotation_file = "/path/to/coco/annotations/instances_val2017.json"

train_transforms = T.Compose([
    T.RandomHorizontalFlip(p=0.5),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = COCODetectionDataset(
    annotation_file=train_annotation_file,
    image_dir=image_dir,
    processor=processor,
    transforms=train_transforms
)
val_dataset = COCODetectionDataset(
    annotation_file=val_annotation_file,
    image_dir=image_dir.replace("train2017", "val2017"),
    processor=processor,
    transforms=None  # No augmentation for validation
)

train_loader = DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn
)
val_loader = DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn
)

# Prepare with Accelerator
train_loader, val_loader, model, optimizer = accelerator.prepare(
    train_loader, val_loader, model, optimizer
)

# 6. Training Function
def train_one_epoch(model, loader, optimizer, device, epoch, accelerator):
    model.train()
    running_loss = 0.0
    for batch in tqdm(loader, desc=f"Epoch {epoch}"):
        pixel_values = batch['pixel_values'].to(device)
        labels = [{k: v.to(device) for k, v in t.items()} for t in batch['labels']]
        
        outputs = model(pixel_values=pixel_values, labels=labels)
        loss = outputs.loss
        
        optimizer.zero_grad()
        accelerator.backward(loss)
        optimizer.step()
        
        running_loss += loss.item()
    
    avg_loss = running_loss / len(loader)
    print(f"Epoch: {epoch}, Train Loss: {avg_loss:.4f}")
    return avg_loss

# 7. Evaluation Function
@torch.no_grad()
def evaluate(model, loader, device, processor, threshold=0.5):
    model.eval()
    total_loss = 0.0
    all_results = []
    for batch in loader:
        pixel_values = batch['pixel_values'].to(device)
        labels = [{k: v.to(device) for k, v in t.items()} for t in batch['labels']]
        target_sizes = batch['size'].to(device)
        
        outputs = model(pixel_values=pixel_values, labels=labels)
        loss = outputs.loss
        total_loss += loss.item()
        
        # Post-process for mAP calculation
        results = processor.post_process_object_detection(
            outputs, target_sizes=target_sizes, threshold=threshold
        )
        all_results.extend(results)
    
    avg_loss = total_loss / len(loader)
    # Note: mAP calculation requires pycocotools
    print(f"Validation Loss: {avg_loss:.4f}")
    return avg_loss, all_results

# 8. Training Loop with Visualization and Early Stopping
train_losses = []
val_losses = []
best_val_loss = float('inf')
epochs_no_improve = 0

for epoch in range(1, num_epochs + 1):
    train_loss = train_one_epoch(model, train_loader, optimizer, device, epoch, accelerator)
    val_loss, detections = evaluate(model, val_loader, device, processor)
    
    # Store losses for visualization
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    
    # Real-time plotting
    clear_output(wait=True)
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Validation Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Training and Validation Loss")
    plt.show()
    
    # Early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        # Save best model
        accelerator.wait_for_everyone()
        unwrapped_model = accelerator.unwrap_model(model)
        torch.save(unwrapped_model.state_dict(), "detr_finetuned.pth")
    else:
        epochs_no_improve += 1
        print(f"No improvement for {epochs_no_improve} epoch(s).")
        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch}. Best val loss: {best_val_loss:.4f}")
            break

# 9. Save Final Model
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
torch.save(unwrapped_model.state_dict(), "detr_finetuned_final.pth")
