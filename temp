# This cell builds a ready-to-run Jupyter notebook that:
# 1) Splits a YOLOv4-style dataset into train/val by a user-set ratio
# 2) Converts labels to COCO format
# 3) Copies images into the requested directory structure:
#    /workspace/images/train, /workspace/images/val
#    /workspace/annotations/instances_train.json, ..._val.json

import json, os, nbformat as nbf

nb = nbf.v4.new_notebook()

cells = []

# 1) Title/Intro
cells.append(nbf.v4.new_markdown_cell("""
# YOLOv4 âžœ COCO Converter & Splitter

This notebook will:
- Read YOLOv4-style labels from `/workspace/tmp` (images + `.txt` label files).
- Split into Train/Val using a ratio you pick.
- Convert annotations to COCO and copy images into:
  - `/workspace/images/train` and `/workspace/images/val`
  - `/workspace/annotations/instances_train.json` and `/workspace/annotations/instances_val.json`

**Notes**
- If `/workspace/tmp/classes.txt` exists, class names will be taken from it (one name per line, index = class id).
- If no `classes.txt`, categories will be auto-named like `class_0`, `class_1`, ...
- Images without a matching label `.txt` will be included with **zero annotations**.
"""))

# 2) Parameters
cells.append(nbf.v4.new_code_cell("""
# ==== User parameters ====
SRC_DIR = "/workspace/tmp"              # Where original YOLO images/labels live
OUT_IMG_DIR = "/workspace/images"       # Will create 'train' and 'val' inside this
OUT_ANN_DIR = "/workspace/annotations"  # Will write COCO JSONs here

# Train/Val split ratio: e.g., 0.8 means 80% train / 20% val
TRAIN_RATIO = 0.8

# Random seed for reproducible splitting
RANDOM_SEED = 42

# Image extensions to consider
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
"""))

# 3) Imports & helpers
cells.append(nbf.v4.new_code_cell("""
import os, shutil, random, json, math
from pathlib import Path
from PIL import Image
from typing import List, Dict, Tuple

random.seed(RANDOM_SEED)

def load_class_names(src_dir: str) -> List[str]:
    classes_path = Path(src_dir) / "classes.txt"
    if classes_path.exists():
        with open(classes_path, "r", encoding="utf-8") as f:
            names = [ln.strip() for ln in f if ln.strip()]
        return names
    return []  # will auto-generate later

def list_images(src_dir: str) -> List[Path]:
    p = Path(src_dir)
    imgs = [fp for fp in p.iterdir() if fp.is_file() and fp.suffix.lower() in IMG_EXTS]
    return sorted(imgs)

def paired_label_path(img_path: Path) -> Path:
    return img_path.with_suffix(".txt")

def read_image_size(img_path: Path) -> Tuple[int, int]:
    with Image.open(img_path) as im:
        w, h = im.size
    return w, h

def ensure_dirs():
    Path(OUT_IMG_DIR, "train").mkdir(parents=True, exist_ok=True)
    Path(OUT_IMG_DIR, "val").mkdir(parents=True, exist_ok=True)
    Path(OUT_ANN_DIR).mkdir(parents=True, exist_ok=True)

def yolo_line_to_bbox_xywh_pix(line: str, W: int, H: int) -> Tuple[int, float, float, float, float]:
    # YOLO format: class x_center y_center width height  (normalized 0..1)
    parts = line.strip().split()
    if len(parts) < 5:
        raise ValueError(f"Bad label line: '{line}'")
    cid = int(parts[0])
    xc, yc, ww, hh = map(float, parts[1:5])
    x = (xc - ww/2.0) * W
    y = (yc - hh/2.0) * H
    w = ww * W
    h = hh * H

    # clip to image bounds
    x = max(0.0, min(x, W - 1.0))
    y = max(0.0, min(y, H - 1.0))
    w = max(0.0, min(w, W - x))
    h = max(0.0, min(h, H - y))
    return cid, x, y, w, h

def make_categories(class_names: List[str], max_class_id: int) -> List[Dict]:
    cats = []
    if class_names:
        for i, name in enumerate(class_names):
            cats.append({"id": i, "name": name, "supercategory": "object"})
    else:
        for i in range(max_class_id + 1):
            cats.append({"id": i, "name": f"class_{i}", "supercategory": "object"})
    return cats
"""))

# 4) Scan dataset and split
cells.append(nbf.v4.new_code_cell("""
# Scan
all_images = list_images(SRC_DIR)
print(f"Found {len(all_images)} images in {SRC_DIR}")

# Derive set of class names (if present)
class_names = load_class_names(SRC_DIR)

# Build pairs (image, label or None)
pairs = []
max_cls_id_seen = -1

for img in all_images:
    lbl = paired_label_path(img)
    pairs.append((img, lbl if lbl.exists() else None))

    # Peek into label to track max class id
    if lbl.exists():
        with open(lbl, "r", encoding="utf-8") as f:
            for ln in f:
                ln = ln.strip()
                if not ln:
                    continue
                cid = int(ln.split()[0])
                if cid > max_cls_id_seen:
                    max_cls_id_seen = cid

print(f"Images with labels: {sum(1 for _, l in pairs if l is not None)}")
print(f"Images without labels: {sum(1 for _, l in pairs if l is None)}")
print(f"Max class id seen: {max_cls_id_seen if max_cls_id_seen >= 0 else 'none (no labels found?)'}")

# Split
N = len(pairs)
train_count = int(round(N * TRAIN_RATIO))
indices = list(range(N))
random.shuffle(indices)
train_idx = set(indices[:train_count])
val_idx   = set(indices[train_count:])

train_pairs = [pairs[i] for i in range(N) if i in train_idx]
val_pairs   = [pairs[i] for i in range(N) if i in val_idx]

print(f"Train images: {len(train_pairs)} | Val images: {len(val_pairs)}")
"""))

# 5) Conversion function
cells.append(nbf.v4.new_code_cell("""
def convert_and_copy(pairs, subset: str, categories: List[Dict]):
    assert subset in {"train","val"}
    images = []
    annotations = []
    ann_id = 1
    img_id = 1

    out_img_dir = Path(OUT_IMG_DIR, subset)
    for img_path, lbl_path in pairs:
        W, H = read_image_size(img_path)
        # Copy image
        dest = out_img_dir / img_path.name
        if str(img_path.resolve()) != str(dest.resolve()):
            shutil.copy2(img_path, dest)

        # Register image in COCO
        images.append({
            "id": img_id,
            "file_name": dest.name,
            "width": W,
            "height": H
        })

        # Parse labels (if any)
        if lbl_path and lbl_path.exists():
            with open(lbl_path, "r", encoding="utf-8") as f:
                for ln in f:
                    ln = ln.strip()
                    if not ln:
                        continue
                    cid, x, y, w, h = yolo_line_to_bbox_xywh_pix(ln, W, H)
                    area = float(w * h)
                    annotations.append({
                        "id": ann_id,
                        "image_id": img_id,
                        "category_id": cid,
                        "bbox": [float(x), float(y), float(w), float(h)],
                        "area": area,
                        "iscrowd": 0,
                        "segmentation": []
                    })
                    ann_id += 1

        img_id += 1

    coco = {
        "info": {
            "description": "Converted from YOLOv4",
            "url": "",
            "version": "1.0",
            "year": 2025,
            "contributor": "",
            "date_created": ""
        },
        "licenses": [],
        "images": images,
        "annotations": annotations,
        "categories": categories
    }
    return coco
"""))

# 6) Run conversion and save JSONs
cells.append(nbf.v4.new_code_cell("""
ensure_dirs()

# Categories (prefer names from classes.txt; else auto-generate)
if class_names:
    categories = [{"id": i, "name": n, "supercategory": "object"} for i, n in enumerate(class_names)]
else:
    categories = make_categories([], max_cls_id_seen if max_cls_id_seen >= 0 else 0)

coco_train = convert_and_copy(train_pairs, "train", categories)
coco_val   = convert_and_copy(val_pairs, "val", categories)

ann_train_path = Path(OUT_ANN_DIR, "instances_train.json")
ann_val_path   = Path(OUT_ANN_DIR, "instances_val.json")

with open(ann_train_path, "w", encoding="utf-8") as f:
    json.dump(coco_train, f, ensure_ascii=False)
with open(ann_val_path, "w", encoding="utf-8") as f:
    json.dump(coco_val, f, ensure_ascii=False)

print("==== Done ====")
print(f"Wrote: {ann_train_path}")
print(f"Wrote: {ann_val_path}")
print(f"Images copied to: {Path(OUT_IMG_DIR, 'train')} and {Path(OUT_IMG_DIR, 'val')}")
print(f"Categories: {[c['name'] for c in categories]}")
print(f"Train: {len(coco_train['images'])} images, {len(coco_train['annotations'])} annotations")
print(f"Val:   {len(coco_val['images'])} images, {len(coco_val['annotations'])} annotations")
"""))

# 7) Optional: quick peek of a few records
cells.append(nbf.v4.new_code_cell("""
# Peek first image & annotation entries (if any)
print("Sample train image record:", coco_train["images"][0] if coco_train["images"] else "None")
print("Sample train annotation record:", coco_train["annotations"][0] if coco_train["annotations"] else "None")
"""))

nb.cells = cells

out_nb_path = "/mnt/data/yolov4_to_coco_split.ipynb"
with open(out_nb_path, "w", encoding="utf-8") as f:
    nbf.write(nb, f)

out_nb_path







